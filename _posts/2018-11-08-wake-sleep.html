---
layout: post
title: Wake-Sleep
---

<p>
Summary of wake-sleep [<a href="#hinton1995wake">1</a>] and reweighted wake-sleep [<a href="#bornschein2014reweighted">2</a>] papers.
</p>

<div id="outline-container-org5a1a26c" class="outline-2">
<h2 id="org5a1a26c"><span class="section-number-2">1</span> Wake-Sleep</h2>
<div class="outline-text-2" id="text-1">
<p>
Rather than attempting to learn \(\theta\) and \(\phi\) to maximise a single loss like e.g. auto-encoders, wake-sleep uses a separate loss for each. \(\theta\) is learned to maximise the ELBO, summed over a dataset. This is a proxy for the model evidence:
\[
\mathcal{L}_p = \sum_{y \in \mathcal{D}} \int q_\phi(x|y) \log \frac{p_\theta(x, y)}{q_\phi(x|y)} = \log p_\theta(y) - D_{KL}(q_\phi(x|y) || p_{\theta}(x|y))
\]
\(\phi\) is learned to minimise the expected KL divergence:
\[
\mathcal{L}_q = -\mathbb{E}_{p_\theta(x)} \left[ D_{KL}(p_\theta(x|y) || q_\phi(x|y) ) \right]
\]
Note that this loss is the p-q KL divergence. If it was the q-p divergence, this would be equivalent to learning \(\phi\) to maximise the ELBO, just like \(\theta\), and this would be equivalent to a VAE. 
</p>
</div>

<div id="outline-container-org3d5d78f" class="outline-3">
<h3 id="org3d5d78f"><span class="section-number-3">1.1</span> Wake Phase</h3>
<div class="outline-text-3" id="text-1-1">
<p>
In the wake phase, the model is trained with the following gradient, using observations, \(y\), sampled from the dataset:
</p>
\begin{align}
\frac{\partial}{\partial \theta} \mathcal{L}_p(\theta, \phi) &= \frac{\partial}{\partial \theta} \sum_{y \in \mathcal{D}} \mathbb{E}_{q_\phi(x|y)} \left[ \log p_\theta(x, y) - \log q_\phi(x|y) \right]\\
                                                             &= \sum_{y \in \mathcal{D}} \mathbb{E}_{q_\phi(x|y)} \left[ \frac{\partial}{\partial \theta} \log p_\theta(x, y) \right]
\end{align}
</div>
</div>
<div id="outline-container-orgf875bd7" class="outline-3">
<h3 id="orgf875bd7"><span class="section-number-3">1.2</span> Sleep phase</h3>
<div class="outline-text-3" id="text-1-2">
<p>
In the sleep phase, the guide is trained according to samples from the model:
</p>
\begin{align}
\frac{\partial}{\partial \phi} \mathcal{L}_q(\theta, \phi) &= - \frac{\partial}{\partial \phi} \mathbb{E}_{p_\theta(x,y)} \left[ \log p_\theta(x|y) - \log q_\phi(x|y) \right] \\
                                                           &= \mathbb{E}_{p_\theta(x,y)} \left[ \frac{\partial}{\partial \phi}  \log q_\phi(x|y) \right]
\end{align}
</div>
</div>
<div id="outline-container-org2186451" class="outline-3">
<h3 id="org2186451"><span class="section-number-3">1.3</span> Notes</h3>
<div class="outline-text-3" id="text-1-3">
<p>
The derivations of the above gradients both rely on the fact that the expectations and derivatives are w.r.t. different things. This means we can always simply exchange the expectation and derivative without the reparameterisation trick or REINFORCE etc. This is particularly useful when we have discrete variables.
</p>
</div>
</div>
</div>

<div id="outline-container-orgd1d029d" class="outline-2">
<h2 id="orgd1d029d"><span class="section-number-2">2</span> Reweighted Wake Sleep</h2>
<div class="outline-text-2" id="text-2">
<p>
This paper replaces the ELBO with a tighter bound on the model evidence (the importance sampling normalisation constant). This is identical to the IWAE, but the we don't have the issues of poor learning of the inference network (since we use a different loss for this).
</p>

<p>
We use a loss given by:
</p>
\begin{equation}
\mathcal{L}_p(\theta, \phi) = \sum_{y \in \mathcal{D}} \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \log \left( \frac{1}{K} \sum_{k=1}^{K} w^{(k)} \right) \right]
\end{equation}
<p>
where \(w^{(k)} = \frac{p(x^{(k)}, y)}{q(x^{(k)} | y)}\) are the unnormalised weights from importance sampling \(p(x|y)\), from a proposal \(Q(x^{(1:K)}|y) = \prod_{k=1}^K q(x^{(k)}|y)\). We can show that this lower bounds the log model evidence:
</p>
\begin{align}
\sum_{y \in \mathcal{D}} \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \log \left( \frac{1}{K} \sum_{k=1}^{K} w^{(k)} \right) \right]
&\leq \sum_{y \in \mathcal{D}} \log \left( \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \frac{1}{K} \sum_{k=1}^{K} w^{(k)} \right] \right) \\
&= \sum_{y \in \mathcal{D}} \log \left( \frac{1}{K} \sum_{k=1}^{K}  \mathbb{E}_{q(x^{(k)}|y)} \left[ w^{(k)} \right] \right) \\
&= \sum_{y \in \mathcal{D}} \log \left( p(y) \right)
\end{align}

<p>
This bound can be made arbitrarily tight by increasing \(K\).
</p>
</div>

<div id="outline-container-orgbadfbfe" class="outline-3">
<h3 id="orgbadfbfe"><span class="section-number-3">2.1</span> Updating \(\theta\)</h3>
<div class="outline-text-3" id="text-2-1">
<p>
We can derive gradients for updating \(\theta\) (sum over \(y \in \mathcal{D}\) left out for clarity):
</p>
\begin{align}
\frac{\partial}{\partial \theta} \mathcal{L}_p(\theta, \phi, y) &= \frac{\partial}{\partial \theta} \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \log \left( \frac{1}{K} \sum_{k=1}^{K} w^{(k)} \right) \right] \\
&= \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \frac{\partial}{\partial \theta} \log \left( \frac{1}{K} \sum_{k=1}^{K} w^{(k)} \right) \right] \\
&= \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \frac{1}{\frac{1}{K} \sum_{k'} w^{(k')}} \frac{\partial}{\partial \theta} \left( \frac{1}{K} \sum_{k=1}^{K} w^{(k)} \right) \right] \\
&= \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \frac{1}{ \sum_{k'} w^{(k')}} \sum_{k=1}^{K} \frac{\partial}{\partial \theta} \frac{p(x^{(k)}, y)}{q(x^{(k)} | y)} \right] \\
&= \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \frac{1}{ \sum_{k'} w^{(k')}} \sum_{k=1}^{K} w^{(k)} \frac{\partial}{\partial \theta} \log p(x^{(k)}, y) \right] \\
&= \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \sum_{k=1}^{K} \hat{w}^{(k)} \frac{\partial}{\partial \theta} \log p(x^{(k)}, y) \right]
\end{align}
</div>
</div>
<div id="outline-container-org8ce6d26" class="outline-3">
<h3 id="org8ce6d26"><span class="section-number-3">2.2</span> Updating \(\phi\)</h3>
<div class="outline-text-3" id="text-2-2">
<p>
As \(\phi\) is trained to the same loss as in standard wake-sleep, it can be updated in exactly the same way during the sleep-phase, with:
</p>
\begin{equation}
\frac{\partial}{\partial \phi} \mathcal{L}_q(\theta, \phi) = \mathbb{E}_{p_\theta(x,y)} \left[ \frac{\partial}{\partial \phi}  \log q_\phi(x|y) \right]
\end{equation}
<p>
We can also use the importance-weighted samples to estimate it in the wake-phase, since they approximate samples from \(p_\theta(x,y)\):
</p>
\begin{equation}
\mathbb{E}_{p_\theta(x,y)} \left[ \frac{\partial}{\partial \phi}  \log q_\phi(x|y) \right] \approx \frac{1}{|\mathcal{D}|} \sum_{x \in \mathcal{D}} \mathbb{E}_{Q(x^{(1:K)}|y)} \left[ \sum_{k=1}^{K} \hat{w}^{(k)} \frac{\partial}{\partial \theta} \log q_\phi(x^{(k)} | y) \right]
\end{equation}
<p>
\(\phi\) can be updated in just the sleep phase, just the wake-phase, or both. Usually the wake-phase update is preferred since it uses \(x\) sampled from the data distribution, as opposed to from the current model, and so should train the inference network to perform better on real-world data.
</p>
</div>
</div>

<div id="outline-container-orgd31147b" class="outline-3">
<h3 id="orgd31147b"><span class="section-number-3">2.3</span> Benefits vs unreweighted</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Less noisy estimates of gradient for model learning. Wake-phase update of inference network optimises guide for true distribution.
</p>


<div id="bibliography">
<h2>References</h2>

<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hinton1995wake">1</a>]
</td>
<td class="bibtexitem">
Geoffrey&nbsp;E Hinton, Peter Dayan, Brendan&nbsp;J Frey, and Radford&nbsp;M Neal.
 The" wake-sleep" algorithm for unsupervised neural networks.
 <em>Science</em>, 268(5214):1158--1161, 1995.

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bornschein2014reweighted">2</a>]
</td>
<td class="bibtexitem">
J&ouml;rg Bornschein and Yoshua Bengio.
 Reweighted wake-sleep.
 <em>arXiv preprint arXiv:1406.2751</em>, 2014.

</td>
</tr>
</table>
</div>
</div>
</div>
</div>
